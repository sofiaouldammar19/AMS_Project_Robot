{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Mar/2025 13:46:05] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Mar/2025 13:46:19] \"GET /chatbot?message=Hello%20chatbot%20how%20are%20you%20?&lang=fr HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, json, request, jsonify, render_template\n",
    "import requests\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import spacy\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Get API keys from environment variables\n",
    "API_KEY = os.getenv(\"WEATHER_API_KEY\")\n",
    "GEMINI_API_WEATHER_KEY = os.getenv(\"GEMINI_API_WEATHER_KEY\")\n",
    "\n",
    "# OpenWeatherMap Endpoints\n",
    "CURRENT_WEATHER_URL = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "FORECAST_URL = \"http://api.openweathermap.org/data/2.5/forecast\"\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=GEMINI_API_WEATHER_KEY)\n",
    "\n",
    "# Load spaCy language models for French and English\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def get_relative_time_phrase(forecast_datetime, lang):\n",
    "    now = datetime.now()\n",
    "    delta = forecast_datetime - now\n",
    "\n",
    "    if delta.total_seconds() <= 0 or delta.total_seconds() >= 24 * 3600:\n",
    "        return forecast_datetime.strftime(\"%A %d %B %Y, %H:%M\")\n",
    "\n",
    "    hours = int(delta.total_seconds() // 3600)\n",
    "    minutes = int((delta.total_seconds() % 3600) // 60)\n",
    "    if hours > 0:\n",
    "        if lang == 'fr':\n",
    "            return f\"dans {hours} heure{'s' if hours > 1 else ''}\"\n",
    "        else:\n",
    "            return f\"in {hours} hour{'s' if hours > 1 else ''}\"\n",
    "    else:\n",
    "        if lang == 'fr':\n",
    "            return f\"dans {minutes} minute{'s' if minutes > 1 else ''}\"\n",
    "        else:\n",
    "            return f\"in {minutes} minute{'s' if minutes > 1 else ''}\"\n",
    "\n",
    "\n",
    "def generate_gemini_response(city, temperature, description, lang, forecast_datetime=None):\n",
    "    if forecast_datetime:\n",
    "        time_phrase = get_relative_time_phrase(forecast_datetime, lang)\n",
    "        if lang == 'fr':\n",
    "            prompt = (\n",
    "                f\"Tu es un chatbot amical. Quelqu'un demande la météo à {city} {time_phrase}. \"\n",
    "                f\"Voici les données : La météo sera {description} avec une température de {temperature}°C. \"\n",
    "                f\"Réponds de manière naturelle et engageante.\"\n",
    "            )\n",
    "        else:\n",
    "            prompt = (\n",
    "                f\"You are a friendly and engaging chatbot. Someone asks about the weather in {city} {time_phrase}. \"\n",
    "                f\"Here’s the data: The weather will be {description} with a temperature of {temperature}°C. \"\n",
    "                f\"Respond in a natural, conversational way.\"\n",
    "            )\n",
    "    else:\n",
    "        if lang == 'fr':\n",
    "            prompt = (\n",
    "                f\"Tu es un chatbot amical. Quelqu'un demande la météo à {city}. \"\n",
    "                f\"Voici les données : La météo est {description} avec une température de {temperature}°C. \"\n",
    "                f\"Réponds de manière naturelle et engageante.\"\n",
    "            )\n",
    "        else:\n",
    "            prompt = (\n",
    "                f\"You are a friendly and engaging chatbot. Someone asks about the weather in {city}. \"\n",
    "                f\"Here’s the data: The weather is {description} with a temperature of {temperature}°C. \"\n",
    "                f\"Respond in a natural, conversational way.\"\n",
    "            )\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text if response else \"Sorry, I couldn't generate a response.\"\n",
    "\n",
    "\n",
    "def get_weather(city, lang, forecast_datetime_str=None):\n",
    "    if forecast_datetime_str:\n",
    "        params = {\n",
    "            \"q\": city,\n",
    "            \"appid\": API_KEY,\n",
    "            \"units\": \"metric\",\n",
    "            \"lang\": lang\n",
    "        }\n",
    "        response = requests.get(FORECAST_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            try:\n",
    "                target_dt = datetime.strptime(\n",
    "                    forecast_datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "            except ValueError:\n",
    "                return {\"error\": \"Invalid datetime format. Use YYYY-MM-DD HH:MM:SS.\"}\n",
    "            forecast_list = data.get(\"list\", [])\n",
    "            if not forecast_list:\n",
    "                return {\"error\": \"Forecast data is unavailable.\"}\n",
    "            closest_forecast = min(\n",
    "                forecast_list,\n",
    "                key=lambda x: abs(datetime.strptime(\n",
    "                    x[\"dt_txt\"], \"%Y-%m-%d %H:%M:%S\") - target_dt)\n",
    "            )\n",
    "            temperature = closest_forecast[\"main\"][\"temp\"]\n",
    "            description = closest_forecast[\"weather\"][0][\"description\"]\n",
    "            city_name = data[\"city\"][\"name\"]\n",
    "\n",
    "            chatbot_response = generate_gemini_response(\n",
    "                city_name, temperature, description, lang, target_dt)\n",
    "            return {\"response\": chatbot_response}\n",
    "        else:\n",
    "            return {\"error\": \"City not found or API request failed.\"}\n",
    "    else:\n",
    "        params = {\n",
    "            \"q\": city,\n",
    "            \"appid\": API_KEY,\n",
    "            \"units\": \"metric\",\n",
    "            \"lang\": lang\n",
    "        }\n",
    "        response = requests.get(CURRENT_WEATHER_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            temperature = data[\"main\"][\"temp\"]\n",
    "            description = data[\"weather\"][0][\"description\"]\n",
    "            city_name = data[\"name\"]\n",
    "\n",
    "            chatbot_response = generate_gemini_response(\n",
    "                city_name, temperature, description, lang)\n",
    "            return {\"response\": chatbot_response}\n",
    "        else:\n",
    "            return {\"error\": \"City not found or API request failed.\"}\n",
    "\n",
    "\n",
    "def is_weather_query(doc, lang):\n",
    "    \"\"\"\n",
    "    Check if the message is likely a weather query based on weather-related keywords.\n",
    "    \"\"\"\n",
    "    if lang == 'fr':\n",
    "        keywords = {\"météo\", \"température\", \"prédiction\",\n",
    "                    \"pluie\", \"ensoleillé\", \"neige\", \"vent\"}\n",
    "    else:\n",
    "        keywords = {\"weather\", \"temperature\",\n",
    "                    \"forecast\", \"rain\", \"sunny\", \"snow\", \"wind\"}\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.lower() in keywords:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_city(doc):\n",
    "    # Check for both GPE and LOC entity labels\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"GPE\", \"LOC\"}:\n",
    "            return ent.text\n",
    "    return None\n",
    "\n",
    "\n",
    "@app.route('/chatbot', methods=['GET'])\n",
    "def chatbot():\n",
    "    user_message = request.args.get(\"message\")\n",
    "    lang = request.args.get(\"lang\", \"fr\")\n",
    "\n",
    "    if not user_message:\n",
    "        return jsonify({\"error\": \"Veuillez saisir un message.\"}), 400\n",
    "\n",
    "    doc = nlp_fr(user_message) if lang == 'fr' else nlp_en(user_message)\n",
    "\n",
    "    if is_weather_query(doc, lang):\n",
    "        city = extract_city(doc)\n",
    "        forecast_datetime_str = None\n",
    "\n",
    "        # First, check for a full datetime pattern (e.g., \"2025-03-05 23:00:00\")\n",
    "        datetime_match = re.search(\n",
    "            r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', user_message)\n",
    "        if datetime_match:\n",
    "            forecast_datetime_str = datetime_match.group(0)\n",
    "        else:\n",
    "            # Try to find a shorthand time pattern like \"23h\"\n",
    "            time_match = re.search(r'(\\d{1,2})h', user_message)\n",
    "            if time_match:\n",
    "                hour = int(time_match.group(1))\n",
    "                now = datetime.now()\n",
    "                # Assume forecast for today\n",
    "                forecast_date = now.date()\n",
    "                forecast_dt = datetime.combine(forecast_date, datetime.min.time()).replace(\n",
    "                    hour=hour, minute=0, second=0)\n",
    "                # If the time is already past, schedule for tomorrow\n",
    "                if forecast_dt < now:\n",
    "                    forecast_dt += timedelta(days=1)\n",
    "                forecast_datetime_str = forecast_dt.strftime(\n",
    "                    \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        if city:\n",
    "            weather_response = get_weather(city, lang, forecast_datetime_str)\n",
    "            return jsonify(weather_response)\n",
    "        else:\n",
    "            clarification = (\n",
    "                \"Je n'ai pas pu détecter le nom de la ville. Pourriez-vous préciser s'il vous plaît ?\"\n",
    "                if lang == 'fr'\n",
    "                else \"I couldn't detect the city name. Could you please specify it?\"\n",
    "            )\n",
    "            return jsonify({\"response\": clarification})\n",
    "\n",
    "    # If not a weather query, proceed with general conversation\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    if lang == 'fr':\n",
    "        prompt = (\n",
    "            f\"Tu es un chatbot amical et engageant. Un étudiant a dit : '{user_message}'. \"\n",
    "            f\"Les entités extraites de cette phrase sont : {entities}. \"\n",
    "            \"Réponds de manière naturelle et utile.\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            f\"You are a friendly and engaging chatbot. A student said: '{user_message}'. \"\n",
    "            f\"The entities extracted from the sentence are: {entities}. \"\n",
    "            \"Please respond in a natural and helpful way.\"\n",
    "        )\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "    response = model.generate_content(prompt)\n",
    "    response_text = response.text if response else \"Sorry, I couldn't generate a response.\"\n",
    "\n",
    "    return jsonify({\"response\": response_text})\n",
    "\n",
    "\n",
    "# Weather-specific endpoint (if needed)\n",
    "@app.route('/chatbot/weather', methods=['GET'])\n",
    "def chatbot_weather():\n",
    "    city = request.args.get(\"city\")\n",
    "    lang = request.args.get(\"lang\", \"fr\")\n",
    "    forecast_datetime_str = request.args.get(\"datetime\")\n",
    "\n",
    "    if lang not in ['fr', 'en']:\n",
    "        return jsonify({\"error\": \"Langue invalide. Choisissez 'fr' pour français ou 'en' pour anglais.\"}), 400\n",
    "\n",
    "    if not city:\n",
    "        return jsonify({\"error\": \"Donnez un nom de ville.\"}), 400\n",
    "\n",
    "    response_data = get_weather(city, lang, forecast_datetime_str)\n",
    "    return app.response_class(\n",
    "        response=json.dumps(response_data, ensure_ascii=False),\n",
    "        status=200,\n",
    "        mimetype='application/json; charset=utf-8'\n",
    "    )\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('chatbotweather.html')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBY3Jrb-b-8V1VPc-DuF-dPIiNfsaFmxcE\")\n",
    "\n",
    "models = genai.list_models()\n",
    "for model in models:\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oulda\\anaconda3\\envs\\ceribot_env\\lib\\site-packages\\flask_limiter\\extension.py:333: UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for production use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Mar/2025 13:44:24] \"GET / HTTP/1.1\" 200 -\n",
      "ERROR:__main__:Exception on /chatbot [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\oulda\\anaconda3\\envs\\ceribot_env\\lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\oulda\\anaconda3\\envs\\ceribot_env\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\oulda\\anaconda3\\envs\\ceribot_env\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\oulda\\anaconda3\\envs\\ceribot_env\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"c:\\Users\\oulda\\anaconda3\\envs\\ceribot_env\\lib\\site-packages\\flask_limiter\\extension.py\", line 1297, in __inner\n",
      "    return cast(R, flask.current_app.ensure_sync(obj)(*a, **k))\n",
      "  File \"c:\\Users\\oulda\\anaconda3\\envs\\ceribot_env\\lib\\site-packages\\flask\\app.py\", line 1890, in ensure_sync\n",
      "    return self.async_to_sync(func)\n",
      "  File \"c:\\Users\\oulda\\anaconda3\\envs\\ceribot_env\\lib\\site-packages\\flask\\app.py\", line 1911, in async_to_sync\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Install Flask with the 'async' extra in order to use async views.\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Mar/2025 13:44:39] \"\u001b[35m\u001b[1mGET /chatbot?message=Hello%20chatbot%20how%20are%20you%20?&lang=fr HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, json, request, jsonify, render_template\n",
    "import httpx\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import spacy\n",
    "import asyncio\n",
    "import logging\n",
    "from flask_caching import Cache\n",
    "from flask_limiter import Limiter\n",
    "from flask_limiter.util import get_remote_address\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Setup logging for debugging and production monitoring\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure caching (simple in-memory cache for demo; use Redis/Memcached in production)\n",
    "cache = Cache(app, config={'CACHE_TYPE': 'simple'})\n",
    "\n",
    "# Configure rate limiting: e.g., 100 requests per minute overall, or 10 per endpoint as needed.\n",
    "limiter = Limiter(key_func=get_remote_address,\n",
    "                  default_limits=[\"100 per minute\"])\n",
    "limiter.init_app(app)\n",
    "\n",
    "# Get API keys from environment variables\n",
    "API_KEY = os.getenv(\"WEATHER_API_KEY\")\n",
    "GEMINI_API_WEATHER_KEY = os.getenv(\"GEMINI_API_WEATHER_KEY\")\n",
    "\n",
    "# OpenWeatherMap Endpoints\n",
    "CURRENT_WEATHER_URL = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "FORECAST_URL = \"http://api.openweathermap.org/data/2.5/forecast\"\n",
    "\n",
    "# Configure Gemini API and reuse the model instance for efficiency\n",
    "genai.configure(api_key=GEMINI_API_WEATHER_KEY)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "\n",
    "# Load spaCy language models for French and English\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def get_relative_time_phrase(forecast_datetime, lang):\n",
    "    now = datetime.now()\n",
    "    delta = forecast_datetime - now\n",
    "\n",
    "    if delta.total_seconds() <= 0 or delta.total_seconds() >= 24 * 3600:\n",
    "        return forecast_datetime.strftime(\"%A %d %B %Y, %H:%M\")\n",
    "\n",
    "    hours = int(delta.total_seconds() // 3600)\n",
    "    minutes = int((delta.total_seconds() % 3600) // 60)\n",
    "    if hours > 0:\n",
    "        if lang == 'fr':\n",
    "            return f\"dans {hours} heure{'s' if hours > 1 else ''}\"\n",
    "        else:\n",
    "            return f\"in {hours} hour{'s' if hours > 1 else ''}\"\n",
    "    else:\n",
    "        if lang == 'fr':\n",
    "            return f\"dans {minutes} minute{'s' if minutes > 1 else ''}\"\n",
    "        else:\n",
    "            return f\"in {minutes} minute{'s' if minutes > 1 else ''}\"\n",
    "\n",
    "\n",
    "async def generate_gemini_response(city, temperature, description, lang, forecast_datetime=None):\n",
    "    if forecast_datetime:\n",
    "        time_phrase = get_relative_time_phrase(forecast_datetime, lang)\n",
    "        if lang == 'fr':\n",
    "            prompt = (\n",
    "                f\"Tu es un chatbot amical. Quelqu'un demande la météo à {city} {time_phrase}. \"\n",
    "                f\"Voici les données : La météo sera {description} avec une température de {temperature}°C. \"\n",
    "                f\"Réponds de manière naturelle et engageante.\"\n",
    "            )\n",
    "        else:\n",
    "            prompt = (\n",
    "                f\"You are a friendly and engaging chatbot. Someone asks about the weather in {city} {time_phrase}. \"\n",
    "                f\"Here’s the data: The weather will be {description} with a temperature of {temperature}°C. \"\n",
    "                f\"Respond in a natural, conversational way.\"\n",
    "            )\n",
    "    else:\n",
    "        if lang == 'fr':\n",
    "            prompt = (\n",
    "                f\"Tu es un chatbot amical. Quelqu'un demande la météo à {city}. \"\n",
    "                f\"Voici les données : La météo est {description} avec une température de {temperature}°C. \"\n",
    "                f\"Réponds de manière naturelle et engageante.\"\n",
    "            )\n",
    "        else:\n",
    "            prompt = (\n",
    "                f\"You are a friendly and engaging chatbot. Someone asks about the weather in {city}. \"\n",
    "                f\"Here’s the data: The weather is {description} with a temperature of {temperature}°C. \"\n",
    "                f\"Respond in a natural, conversational way.\"\n",
    "            )\n",
    "    try:\n",
    "        # Run the Gemini API call in a separate thread to avoid blocking\n",
    "        response = await asyncio.to_thread(gemini_model.generate_content, prompt)\n",
    "        return response.text if response else \"Sorry, I couldn't generate a response.\"\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Error generating Gemini response\")\n",
    "        return \"Sorry, an error occurred while generating a response.\"\n",
    "\n",
    "\n",
    "# Cache weather API responses for 60 seconds to improve performance\n",
    "@cache.memoize(timeout=60)\n",
    "async def fetch_weather(url, params):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "async def get_weather(city, lang, forecast_datetime_str=None):\n",
    "    try:\n",
    "        if forecast_datetime_str:\n",
    "            params = {\n",
    "                \"q\": city,\n",
    "                \"appid\": API_KEY,\n",
    "                \"units\": \"metric\",\n",
    "                \"lang\": lang\n",
    "            }\n",
    "            data = await fetch_weather(FORECAST_URL, params)\n",
    "            try:\n",
    "                target_dt = datetime.strptime(\n",
    "                    forecast_datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "            except ValueError:\n",
    "                return {\"error\": \"Invalid datetime format. Use YYYY-MM-DD HH:MM:SS.\"}\n",
    "            forecast_list = data.get(\"list\", [])\n",
    "            if not forecast_list:\n",
    "                return {\"error\": \"Forecast data is unavailable.\"}\n",
    "            closest_forecast = min(\n",
    "                forecast_list,\n",
    "                key=lambda x: abs(datetime.strptime(\n",
    "                    x[\"dt_txt\"], \"%Y-%m-%d %H:%M:%S\") - target_dt)\n",
    "            )\n",
    "            temperature = closest_forecast[\"main\"][\"temp\"]\n",
    "            description = closest_forecast[\"weather\"][0][\"description\"]\n",
    "            city_name = data[\"city\"][\"name\"]\n",
    "\n",
    "            chatbot_response = await generate_gemini_response(city_name, temperature, description, lang, target_dt)\n",
    "            return {\"response\": chatbot_response}\n",
    "        else:\n",
    "            params = {\n",
    "                \"q\": city,\n",
    "                \"appid\": API_KEY,\n",
    "                \"units\": \"metric\",\n",
    "                \"lang\": lang\n",
    "            }\n",
    "            data = await fetch_weather(CURRENT_WEATHER_URL, params)\n",
    "            temperature = data[\"main\"][\"temp\"]\n",
    "            description = data[\"weather\"][0][\"description\"]\n",
    "            city_name = data[\"name\"]\n",
    "\n",
    "            chatbot_response = await generate_gemini_response(city_name, temperature, description, lang)\n",
    "            return {\"response\": chatbot_response}\n",
    "    except httpx.RequestError as e:\n",
    "        logger.exception(\"Network error when fetching weather\")\n",
    "        return {\"error\": \"Network error occurred. Please try again later.\"}\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        logger.exception(\"HTTP error when fetching weather\")\n",
    "        return {\"error\": \"City not found or API request failed.\"}\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Unexpected error in get_weather\")\n",
    "        return {\"error\": \"An unexpected error occurred.\"}\n",
    "\n",
    "\n",
    "def is_weather_query(doc, lang):\n",
    "    \"\"\"\n",
    "    Check if the message is likely a weather query based on weather-related keywords.\n",
    "    \"\"\"\n",
    "    if lang == 'fr':\n",
    "        keywords = {\"météo\", \"température\", \"prédiction\",\n",
    "                    \"pluie\", \"ensoleillé\", \"neige\", \"vent\"}\n",
    "    else:\n",
    "        keywords = {\"weather\", \"temperature\",\n",
    "                    \"forecast\", \"rain\", \"sunny\", \"snow\", \"wind\"}\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.lower() in keywords:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_city(doc):\n",
    "    # Check for both GPE and LOC entity labels using spaCy\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"GPE\", \"LOC\"}:\n",
    "            return ent.text\n",
    "    return None\n",
    "\n",
    "\n",
    "@app.route('/chatbot', methods=['GET'])\n",
    "@limiter.limit(\"10 per minute\")\n",
    "async def chatbot():\n",
    "    user_message = request.args.get(\"message\")\n",
    "    lang = request.args.get(\"lang\", \"fr\")\n",
    "\n",
    "    if not user_message:\n",
    "        return jsonify({\"error\": \"Veuillez saisir un message.\"}), 400\n",
    "\n",
    "    doc = nlp_fr(user_message) if lang == 'fr' else nlp_en(user_message)\n",
    "\n",
    "    if is_weather_query(doc, lang):\n",
    "        city = extract_city(doc)\n",
    "        forecast_datetime_str = None\n",
    "\n",
    "        # First, check for a full datetime pattern (e.g., \"2025-03-05 23:00:00\")\n",
    "        datetime_match = re.search(\n",
    "            r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', user_message)\n",
    "        if datetime_match:\n",
    "            forecast_datetime_str = datetime_match.group(0)\n",
    "        else:\n",
    "            # Try to find a shorthand time pattern like \"23h\"\n",
    "            time_match = re.search(r'(\\d{1,2})h', user_message)\n",
    "            if time_match:\n",
    "                hour = int(time_match.group(1))\n",
    "                now = datetime.now()\n",
    "                forecast_date = now.date()\n",
    "                forecast_dt = datetime.combine(forecast_date, datetime.min.time()).replace(\n",
    "                    hour=hour, minute=0, second=0)\n",
    "                if forecast_dt < now:\n",
    "                    forecast_dt += timedelta(days=1)\n",
    "                forecast_datetime_str = forecast_dt.strftime(\n",
    "                    \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        if city:\n",
    "            weather_response = await get_weather(city, lang, forecast_datetime_str)\n",
    "            return jsonify(weather_response)\n",
    "        else:\n",
    "            clarification = (\n",
    "                \"Je n'ai pas pu détecter le nom de la ville. Pourriez-vous préciser s'il vous plaît ?\"\n",
    "                if lang == 'fr'\n",
    "                else \"I couldn't detect the city name. Could you please specify it?\"\n",
    "            )\n",
    "            return jsonify({\"response\": clarification})\n",
    "\n",
    "    # If not a weather query, proceed with general conversation\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    if lang == 'fr':\n",
    "        prompt = (\n",
    "            f\"Tu es un chatbot amical et engageant. Un étudiant a dit : '{user_message}'. \"\n",
    "            f\"Les entités extraites de cette phrase sont : {entities}. \"\n",
    "            \"Réponds de manière naturelle et utile.\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            f\"You are a friendly and engaging chatbot. A student said: '{user_message}'. \"\n",
    "            f\"The entities extracted from the sentence are: {entities}. \"\n",
    "            \"Please respond in a natural and helpful way.\"\n",
    "        )\n",
    "    try:\n",
    "        response = await asyncio.to_thread(gemini_model.generate_content, prompt)\n",
    "        response_text = response.text if response else \"Sorry, I couldn't generate a response.\"\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Error generating general chatbot response\")\n",
    "        response_text = \"Sorry, an error occurred while generating a response.\"\n",
    "\n",
    "    return jsonify({\"response\": response_text})\n",
    "\n",
    "\n",
    "@app.route('/chatbot/weather', methods=['GET'])\n",
    "@limiter.limit(\"10 per minute\")\n",
    "async def chatbot_weather():\n",
    "    city = request.args.get(\"city\")\n",
    "    lang = request.args.get(\"lang\", \"fr\")\n",
    "    forecast_datetime_str = request.args.get(\"datetime\")\n",
    "\n",
    "    if lang not in ['fr', 'en']:\n",
    "        return jsonify({\"error\": \"Langue invalide. Choisissez 'fr' pour français ou 'en' pour anglais.\"}), 400\n",
    "\n",
    "    if not city:\n",
    "        return jsonify({\"error\": \"Donnez un nom de ville.\"}), 400\n",
    "\n",
    "    response_data = await get_weather(city, lang, forecast_datetime_str)\n",
    "    return app.response_class(\n",
    "        response=json.dumps(response_data, ensure_ascii=False),\n",
    "        status=200,\n",
    "        mimetype='application/json; charset=utf-8'\n",
    "    )\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('chatbotweather.html')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceribot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
